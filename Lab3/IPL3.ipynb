{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d958d2-9f5a-4e87-8e25-5a46559fa1b0",
   "metadata": {},
   "source": [
    "# Image Processing: Lab3. 8MA2 , 2210002182"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ae9d0-671b-4534-9c36-3ba3fb4088d0",
   "metadata": {},
   "source": [
    "## Read an image using the OpenCV library\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f0dcdf-96e1-48ff-82a5-4903640c4f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('ronaldo.jpg')\n",
    "cv2.imshow('Input image', img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45b2b78-8191-4432-b712-760eba4f3e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('ronaldo.jpg')\n",
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0019d15-6881-4f59-a66a-059d40091ad2",
   "metadata": {},
   "source": [
    "### Load an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9861e2f1-315f-466f-96b2-e272cfee0a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img = cv2.imread('ronaldo.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow('Grayscale', gray_img)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a04992-5ce1-48b5-9f47-d72e0593a0f3",
   "metadata": {},
   "source": [
    "### Save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3b434-9120-41c0-a768-66d9cda48e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('ronaldo.jpg', gray_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd204329-b753-4e52-8c43-264f023a0ed2",
   "metadata": {},
   "source": [
    "# Task 1 — Geometric Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f127d-8ae9-4c29-9be7-f8dfa0227ebf",
   "metadata": {},
   "source": [
    "### Increase the size of the image (Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ee95a8-9215-4cbd-b165-d5c90d8e8c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('Luffy.jpg') \n",
    "# Scale by 2x \n",
    "scaled_img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
    "cv2.imshow(\"Scaled Image\", scaled_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd2038-cebf-4a13-983a-121206562940",
   "metadata": {},
   "source": [
    "### Rotate the image by 120 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b914017-2989-4d29-a630-cb35fc41344b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(h, w) = img.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "\n",
    "M = cv2.getRotationMatrix2D(center, 120, 1.0)\n",
    "rotated_img = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "cv2.imshow(\"Rotated 120°\", rotated_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73862c98-b6e2-42b3-8e70-9efaccc638f9",
   "metadata": {},
   "source": [
    "### Perform Shear (Shear Transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c247b43e-04a9-434f-a604-1c210bb1dde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shear_factor = 0.5\n",
    "\n",
    "M_shear = np.float32([[1, shear_factor, 0],\n",
    "                      [0, 1, 0]])\n",
    "\n",
    "sheared_img = cv2.warpAffine(img, M_shear, (int(w + h*shear_factor), h))\n",
    "\n",
    "cv2.imshow(\"Sheared Image\", sheared_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680a8fe-7ad9-4450-aa19-4e73b177993c",
   "metadata": {},
   "source": [
    "# Task 2 — Intensity Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a0e20-7cbf-46c3-bfd9-3d678d08dd8e",
   "metadata": {},
   "source": [
    "### Negative Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9158f3a-a123-4247-b107-40db6959c2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "negative_img = 255 - gray\n",
    "\n",
    "cv2.imshow(\"Negative Image\", negative_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fd0058-9c64-4335-9401-99bbcb531570",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6809b6d-f0c2-43dd-9a30-5b21c22208b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "c = -40\n",
    "log_img = c * np.log1p(gray.astype(np.float32)) \n",
    "log_img = cv2.normalize(log_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8) \n",
    "cv2.imshow(\"Log Transformation\", log_img) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e025c7-c173-4ce7-a2c1-9329c093628c",
   "metadata": {},
   "source": [
    "### Power-Law (Gamma) Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f90600c2-4e2a-4b89-b7e7-72904df63f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 0.5\n",
    "gamma_img = np.array(255 * (gray / 255) ** gamma, dtype='uint8')\n",
    "\n",
    "cv2.imshow(\"Gamma Corrected\", gamma_img)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
